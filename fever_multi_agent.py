"""
FEVER Multi-Agent System with Real Vector DB
filtered_train.jsonlì—ì„œ claimì„ ì½ê³  Vector DBì—ì„œ ê·¼ê±°ë¥¼ ê²€ìƒ‰í•˜ì—¬ ë‹µë³€ ìƒì„±
"""
import os
import json
import random
from dotenv import load_dotenv
from openai import OpenAI
from crewai import Agent, Task, Crew, Process
import psycopg2
from pgvector.psycopg2 import register_vector
import numpy as np

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
print(f"API Key loaded: {os.getenv('OPENAI_API_KEY')[:10]}...")


print("Connecting to DB...")
# ---------------------------
# Vector DB Connection
# ---------------------------
def connect_db():
    """Vector DB ì—°ê²°"""
    conn = psycopg2.connect(
        host="localhost",
        port=5432,
        database="postgres",
        user="postgres",
        password="mypassword"
    )
    register_vector(conn)
    print("âœ… DB Connected!")
    return conn

'''
def get_embedding(text, model="text-embedding-3-small"):
    """OpenAIë¡œ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±"""
    response = client.embeddings.create(
        input=text,
        model=model,
        dimensions=768
    )
    return response.data[0].embedding
'''
    
    # sentence-transformers ì¶”ê°€
from sentence_transformers import SentenceTransformer

# ì „ì—­ ë³€ìˆ˜ë¡œ ëª¨ë¸ ë¡œë“œ (í•œ ë²ˆë§Œ)
embedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')

def get_embedding(text):
    """sentence-transformersë¡œ ì„ë² ë”© ìƒì„± (768ì°¨ì›)"""
    return embedding_model.encode(text).tolist()

def retrieve_from_vectordb(query, k=5):
    """Vector DBì—ì„œ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰"""
    conn = connect_db()
    cur = conn.cursor()
    
    # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
    query_embedding = get_embedding(query)
    
    # Vector ê²€ìƒ‰ (L2 distance)
    cur.execute("""
        SELECT 
            id,
            content,
            embedding <-> %s::vector AS distance
        FROM fever_documents
        ORDER BY distance
        LIMIT %s;
    """, (query_embedding, k))
    
    results = cur.fetchall()
    conn.close()
    
    # ë¬¸ì„œ ë‚´ìš©ë§Œ ë°˜í™˜
    docs = [row[1] for row in results if row[1]]
    return docs

# ---------------------------
# Agents ì •ì˜
# ---------------------------
retriever_agent = Agent(
    role="Retriever",
    goal="ì§ˆë¬¸ì— ê°€ì¥ ê´€ë ¨ ìˆëŠ” ë¬¸ì„œë¥¼ Vector DBì—ì„œ ê²€ìƒ‰í•´ ì œê³µí•œë‹¤.",
    backstory="pgvectorë¥¼ í†µí•´ semantic searchë¥¼ ìˆ˜í–‰í•˜ëŠ” ê²€ìƒ‰ ì „ë¬¸ê°€",
    verbose=True,
    allow_delegation=False
)

answerer_agent = Agent(
    role="Answerer",
    goal="ê·¼ê±°ë¥¼ ë°”íƒ•ìœ¼ë¡œ claimì˜ ì§„ìœ„ë¥¼ íŒë‹¨í•˜ê³  ì´ˆì•ˆì„ ìƒì„±í•œë‹¤.",
    backstory="FEVER ë°ì´í„°ì…‹ì˜ fact verification ì „ë¬¸ê°€. SUPPORTS/REFUTES/NOT ENOUGH INFOë¥¼ íŒë‹¨",
    verbose=True,
    allow_delegation=False
)

judge_agent = Agent(
    role="Judge",
    goal="ì—¬ëŸ¬ ì´ˆì•ˆì„ ë¹„êµí•´ ê°€ì¥ ì‚¬ì‹¤ì„± ìˆëŠ” ë‹µë³€ì„ ì„ íƒí•œë‹¤.",
    backstory="ì‚¬ì‹¤ ê²€ì¦ê³¼ ì¼ê´€ì„± í‰ê°€ ì „ë¬¸ê°€. ê·¼ê±°ì™€ì˜ ì •í•©ì„±ì„ ì¤‘ì‹œ",
    verbose=True,
    allow_delegation=False
)

editor_agent = Agent(
    role="Editor",
    goal="ìµœì¢… ë‹µë³€ì„ ëª…í™•í•˜ê³  ë…¼ë¦¬ì ì¸ í˜•ì‹ìœ¼ë¡œ ë‹¤ë“¬ëŠ”ë‹¤.",
    backstory="í•™ìˆ  ë…¼ë¬¸ ìˆ˜ì¤€ì˜ í¸ì§‘ ê¸°ì¤€ì„ ë§ì¶”ëŠ” ì „ë¬¸ê°€",
    verbose=True,
    allow_delegation=False
)

# ---------------------------
# Task í•¨ìˆ˜ë“¤
# ---------------------------
def retriever_task_fn(claim, k=5):
    """Vector DBì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰"""
    print(f"\nğŸ” Retrieving documents for: {claim}")
    docs = retrieve_from_vectordb(claim, k=k)
    context = "\n\n".join([f"[Doc {i+1}] {doc}" for i, doc in enumerate(docs)])
    print(f"âœ… Retrieved {len(docs)} documents")
    return {"context": context, "docs": docs}

def answerer_task_fn(claim, context, style="balanced", temp=0.3):
    """ê·¼ê±°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ ìƒì„±"""
    prompt = f"""
You are a fact-checking expert for the FEVER dataset.

Claim: {claim}

Evidence from database:
{context}

Task: Determine if the claim is:
- SUPPORTS (evidence supports the claim)
- REFUTES (evidence contradicts the claim)  
- NOT ENOUGH INFO (insufficient evidence)

Provide:
1. Label: [SUPPORTS/REFUTES/NOT ENOUGH INFO]
2. Reasoning: Brief explanation
3. Key evidence: Which documents are most relevant

Style: {style}
"""
    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        temperature=temp,
        messages=[
            {"role": "system", "content": "You are a FEVER fact-checking expert."},
            {"role": "user", "content": prompt}
        ]
    )
    return resp.choices[0].message.content

def judge_task_fn(answers, docs, mode="llm"):
    """ì—¬ëŸ¬ ë‹µë³€ ì¤‘ ìµœì„  ì„ íƒ"""
    context = "\n\n".join([f"[Doc {i+1}] {doc}" for i, doc in enumerate(docs)])
    
    if mode == "voting":
        # ê°„ë‹¨í•œ íˆ¬í‘œ ë°©ì‹
        labels = []
        for ans in answers:
            if "SUPPORTS" in ans.upper():
                labels.append("SUPPORTS")
            elif "REFUTES" in ans.upper():
                labels.append("REFUTES")
            else:
                labels.append("NOT ENOUGH INFO")
        return max(set(labels), key=labels.count)
    else:
        # LLM íŒë‹¨
        prompt = f"""
We have multiple draft fact-check results:

{json.dumps(answers, ensure_ascii=False, indent=2)}

Original evidence:
{context}

Task:
1. Choose the most accurate verdict (SUPPORTS/REFUTES/NOT ENOUGH INFO)
2. Provide confidence score (0-1)
3. Explain which draft is most reliable and why
"""
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            temperature=0.2,
            messages=[
                {"role": "system", "content": "You are an impartial fact-checking judge."},
                {"role": "user", "content": prompt}
            ]
        )
        return resp.choices[0].message.content

def editor_task_fn(text, strength="light"):
    """ìµœì¢… í¸ì§‘"""
    if strength == "light":
        prompt = f"Polish grammar and clarity, keep original reasoning:\n\n{text}"
    else:
        prompt = f"Rewrite in clear academic style with structured reasoning:\n\n{text}"
    
    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        temperature=0.1,
        messages=[
            {"role": "system", "content": "You are an academic editor."},
            {"role": "user", "content": prompt}
        ]
    )
    return resp.choices[0].message.content

# ---------------------------
# Pipeline
# ---------------------------
def run_fever_pipeline(claim, k=5, judge_mode="llm", editor_strength="strong"):
    """FEVER claimì— ëŒ€í•œ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    print(f"\n{'='*60}")
    print(f"Processing Claim: {claim}")
    print(f"{'='*60}")
    
    # (1) Retriever: Vector DBì—ì„œ ê²€ìƒ‰
    retr = retriever_task_fn(claim, k)
    context, docs = retr["context"], retr["docs"]

    # (2) Answerer: ì—¬ëŸ¬ ìŠ¤íƒ€ì¼ë¡œ ë‹µë³€ ìƒì„±
    print("\nğŸ“ Generating answers with different styles...")
    answers = []
    styles = ["precise", "balanced", "creative"]
    for style in styles:
        print(f"  - Style: {style}")
        ans = answerer_task_fn(claim, context, style=style, temp=0.7)
        answers.append(ans)

    # (3) Judge: ìµœì„ ì˜ ë‹µë³€ ì„ íƒ
    print("\nâš–ï¸ Judging answers...")
    judged = judge_task_fn(answers, docs, mode=judge_mode)

    # (4) Editor: ìµœì¢… í¸ì§‘
    print("\nâœï¸ Editing final answer...")
    final = editor_task_fn(judged, strength=editor_strength)

    return {
        "claim": claim,
        "docs": docs,
        "answers": answers,
        "judged": judged,
        "final": final
    }

# ---------------------------
# JSONL íŒŒì¼ ì²˜ë¦¬
# ---------------------------
def load_claims_from_jsonl(filepath, limit=5):
    """filtered_train.jsonlì—ì„œ claim ë¡œë“œ"""
    claims = []
    with open(filepath, 'r', encoding='utf-8') as f:
        for i, line in enumerate(f):
            if i >= limit:
                break
            data = json.loads(line)
            claims.append({
                "id": data.get("id"),
                "claim": data.get("claim"),
                "label": data.get("label")  # ì •ë‹µ ë ˆì´ë¸”
            })
    return claims

def evaluate_predictions(results):
    """ì˜ˆì¸¡ ê²°ê³¼ í‰ê°€"""
    correct = 0
    total = len(results)
    
    for res in results:
        predicted = res["final"].upper()
        ground_truth = res["label"].upper()
        
        # ê°„ë‹¨í•œ ë§¤ì¹­ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ íŒŒì‹± í•„ìš”)
        if ground_truth in predicted:
            correct += 1
    
    accuracy = correct / total if total > 0 else 0
    print(f"\n{'='*60}")
    print(f"Evaluation Results:")
    print(f"  Total: {total}")
    print(f"  Correct: {correct}")
    print(f"  Accuracy: {accuracy:.2%}")
    print(f"{'='*60}")
    
    return accuracy

# ---------------------------
# Main
# ---------------------------
if __name__ == "__main__":
    # JSONL íŒŒì¼ ê²½ë¡œ
    JSONL_PATH = r"your/path/to/filtered_train.jsonl"
    
    # í…ŒìŠ¤íŠ¸í•  claim ìˆ˜
    NUM_CLAIMS = 3
    
    print("ğŸš€ FEVER Multi-Agent System Starting...")
    print(f"Loading {NUM_CLAIMS} claims from {JSONL_PATH}\n")
    
    # Claim ë¡œë“œ
    claims = load_claims_from_jsonl(JSONL_PATH, limit=NUM_CLAIMS)
    
    # ê° claimì— ëŒ€í•´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    results = []
    for i, claim_data in enumerate(claims):
        print(f"\n\n{'#'*60}")
        print(f"CLAIM {i+1}/{NUM_CLAIMS}")
        print(f"Ground Truth: {claim_data['label']}")
        print(f"{'#'*60}")
        
        result = run_fever_pipeline(
            claim=claim_data["claim"],
            k=5,
            judge_mode="llm",
            editor_strength="strong"
        )
        
        result["label"] = claim_data["label"]  # ì •ë‹µ ì¶”ê°€
        results.append(result)
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“Š RESULT for Claim {i+1}:")
        print(f"Claim: {result['claim']}")
        print(f"\nFinal Answer:\n{result['final']}")
        print(f"\nGround Truth: {claim_data['label']}")
    
    # ì „ì²´ í‰ê°€
    evaluate_predictions(results)
    
    # ê²°ê³¼ ì €ì¥
    output_file = "fever_results.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    print(f"\nâœ… Results saved to {output_file}")